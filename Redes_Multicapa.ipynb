{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPCizB1qOHeZehQcncg/2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jabarcmun/Int-Artif/blob/main/Redes_Multicapa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XOR\n",
        "\n",
        "Vamos a mostrar el caso clásico del uso de redes neuronales para resolver el problema de la operación lógica `XOR`.\n",
        "\n",
        "El problema XOR (exclusive OR) se define así:\n",
        "\n",
        "| x₁ | x₂ | y = x₁ XOR x₂ |\n",
        "| -- | -- | ------------- |\n",
        "| 0  | 0  | 0             |\n",
        "| 0  | 1  | 1             |\n",
        "| 1  | 0  | 1             |\n",
        "| 1  | 1  | 0             |\n",
        "\n",
        "{% hint style=\"info\" %}\n",
        "Recordemos que este problema no se puede resolver con un perceptrón simple, porque no es linealmente separable. Necesitamos una red multicapa con al menos una capa oculta y activaciones no lineales&#x20;\n",
        "{% endhint %}\n",
        "\n",
        "### Datos\n",
        "\n",
        "Los datos los traduccimos a lenguaje computacional de la siguiente manera\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Datos XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "```\n",
        "\n",
        "### Red neuronal multicapa\n",
        "\n",
        "Definir el modelo de red neuronal\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "modelo = Sequential([\n",
        "    Dense(4, activation='relu', input_dim=2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "```\n",
        "\n",
        "Se utiliza `Sequential` para definir el modelo de red neuronal.\n",
        "\n",
        "Se añaden capas de entrada y ocultas densamente conectadas (`Dense`) con activación ReLU y una capa de salida con activación sigmoide para clasificar la respuesta en 1 y 0 (2 clases).\n",
        "\n",
        "#### **Compilar el modelo**\n",
        "\n",
        "Crear un optimizador Adam con una tasa de aprendizaje del 0.01\n",
        "\n",
        "<pre class=\"language-python\"><code class=\"lang-python\">from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Tasa de aprendizaje deseada\n",
        "<strong>learning_rate = 0.01\n",
        "</strong>adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "</code></pre>\n",
        "\n",
        "```python\n",
        "modelo.compile(\n",
        "    optimizer=adam_optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "```\n",
        "\n",
        "Se compila el modelo utilizando el optimizador Adam y la función de pérdida de entropía cruzada categórica dispersa (`binary_crossentropy`) para la clasificación.\n",
        "\n",
        "También se puede usar directamente el nombre del optimizador ('adam') en el argumento `optimizer` de la función `compile`. En lugar de definir un optimizador personalizado.\n",
        "\n",
        "#### **Entrenar el modelo**\n",
        "\n",
        "```python\n",
        "history = modelo.fit(\n",
        "    X, y,\n",
        "    epochs=50,\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "```\n",
        "\n",
        "Se entrena el modelo en los datos de entrenamiento utilizando `fit`. Se especifica el número de épocas a realizar durante el entrenamiento.\n",
        "\n",
        "### Gráficando la funcion de pérdida\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Evolución de la pérdida (Loss)')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Binary Cross-Entropy')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "Se nota que la función de pérdida debe tender hacia cero.\n",
        "\n",
        "#### Evaluación\n",
        "\n",
        "**Evaluar el modelo en el conjunto de prueba**\n",
        "\n",
        "```python\n",
        "loss, accuracy = modelo.evaluate(X, y)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "```\n",
        "\n",
        "Se evalúa el rendimiento del modelo en el conjunto de prueba utilizando `evaluate`. Se obtienen la pérdida y la precisión del modelo en los datos de prueba.\n",
        "\n",
        "#### Predicción\n",
        "\n",
        "Hacer predicciones y comparar las predicciones con los valores reales\n",
        "\n",
        "```python\n",
        "pred = (modelo.predict(X) > 0.5).astype(int)\n",
        "for i, (inp, p) in enumerate(zip(X, pred)):\n",
        "    print(f\"{inp} -> {p[0]}\")\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "g2TuDu7P99CA",
        "outputId": "45238db3-a720-464c-a1ec-a7fa074f6f7c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid character '₁' (U+2081) (ipython-input-1212114868.py, line 7)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1212114868.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    | x₁ | x₂ | y = x₁ XOR x₂ |\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '₁' (U+2081)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Datos XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])"
      ],
      "metadata": {
        "id": "lUY5DYHp-bzt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "modelo = Sequential([\n",
        "    Dense(4, activation='relu', input_dim=2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "qoTO3LK3_OKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Tasa de aprendizaje deseada\n",
        "learning_rate = 0.01\n",
        "adam_optimizer = Adam(learning_rate=learning_rate)"
      ],
      "metadata": {
        "id": "lUgHcpnV_S4y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.compile(\n",
        "    optimizer=adam_optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "SQL_C3gA_ZtX",
        "outputId": "5bf7ce18-3073-43fc-b9c9-5b503634416e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'modelo' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2536181293.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m modelo.compile(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madam_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'modelo' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.compile(\n",
        "    optimizer=adam_optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "fkfRAhit_pSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = modelo.fit(\n",
        "    X, y,\n",
        "    epochs=50,\n",
        "    verbose=0,\n",
        ")"
      ],
      "metadata": {
        "id": "pnjubc8g_xwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Evolución de la pérdida (Loss)')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Binary Cross-Entropy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1KPwZmgX_4D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = modelo.evaluate(X, y)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "KC23i-xw_9eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = (modelo.predict(X) > 0.5).astype(int)\n",
        "for i, (inp, p) in enumerate(zip(X, pred)):\n",
        "    print(f\"{inp} -> {p[0]}\")"
      ],
      "metadata": {
        "id": "Ld0m-ch0AFIJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}